Ниже приведены два раздела:

1. **Инструкция в формате Markdown** – аккуратно оформленный порядок действий для ручной настройки кластера.

2. **Скрипт автоматизации** – пример единого скрипта на Bash, который пытается максимально автоматизировать развёртывание Hadoop-кластера.  
   - Скрипт рассчитан на запуск **из-под пользователя `team`** на ноде JournalNode (tmpl-jn).  
   - При этом **необходимо**, чтобы на этой ноде был установлен пакет `sshpass` (используется для передачи пароля по SSH).  
   - Скрипт использует две переменные окружения: `TEAM_PASSWORD` (пароль от пользователя `team`) и `HADOOP_USER_PASSWORD` (пароль для создаваемого пользователя `hadoop`).  
   - Если вы не можете установить `sshpass` или нуждаетесь в более гибкой схеме (например, с использованием `expect`), вы можете разбить процесс на несколько скриптов, вручную вводя пароли там, где это требуется.  

---

## 1. Инструкция по развертыванию (Markdown)

Ниже представлена инструкция, которую вы можете **скопировать** и сохранить в файл с расширением `.md` (например, `deploy-hadoop.md`).


# Развёртывание Hadoop-кластера на 4 нодах

В данном руководстве описаны шаги по настройке кластера Hadoop 3.4.0 на четырёх нодах:
- JournalNode (tmpl-jn) – 192.168.1.142
- NameNode (tmpl-nn) – 192.168.1.143
- DataNode 1 (tmpl-dn-00) – 192.168.1.144
- DataNode 2 (tmpl-dn-01) – 192.168.1.145

## Предварительные требования

1. **Java 11** (или совместимая с Hadoop) должна быть установлена на всех нодах. Для проверки:
   ```bash
   java --version
   ```
2. Наличие сетевого доступа по SSH к каждой ноде.
3. Пароль пользователя `team` доступен (используется для подключения по SSH).
4. (Опционально) Удобно иметь установленный пакет `sshpass` (для автоматизации).

## Шаги установки и настройки

### 1. Подключение к нодам по SSH

Подключаемся к каждой из нод по очереди:
```bash
ssh team@192.168.1.142  # tmpl-jn
ssh team@192.168.1.143  # tmpl-nn
ssh team@192.168.1.144  # tmpl-dn-00
ssh team@192.168.1.145  # tmpl-dn-01
```
Пароль берём из переменной (к примеру, `TEAM_PASSWORD`).

### 2. Создаём пользователя `hadoop`

На каждой ноде (tmpl-jn, tmpl-nn, tmpl-dn-00, tmpl-dn-01) выполняем:
```bash
sudo adduser hadoop
```
И устанавливаем пароль (например, введя `HADOOP_USER_PASSWORD`).

### 3. Настройка `/etc/hosts`

На **каждой** ноде в файле `/etc/hosts` добавляем (или меняем) следующие записи:

- Для JournalNode (`tmpl-jn`) — важно **закомментировать строку** с `192.168.1.142 tmpl-jn`, прописав вместо localhost:
  ```bash
  127.0.0.1 tmpl-jn
  # 192.168.1.142 tmpl-jn
  192.168.1.143 tmpl-nn
  192.168.1.144 tmpl-dn-00
  192.168.1.145 tmpl-dn-01
  ```
- Для NameNode (`tmpl-nn`) — не нужно комментировать строку с собственным IP. Достаточно убедиться, что прописаны все 4 строки (включая 192.168.1.143 tmpl-nn).
- Для DataNode 1 и DataNode 2 — аналогично принципу, что на локальном узле IP комментируем, а `127.0.0.1` ставим с соответствующим hostname.

Далее проверяем:
```bash
ping tmpl-nn
ping tmpl-dn-00
ping tmpl-dn-01
```

### 4. Переходим под пользователя `hadoop` и запускаем tmux

```bash
sudo -i -u hadoop
tmux
```
tmux позволит оставить запущенными в фоновом режиме длительные процессы (например, скачивание Hadoop).

### 5. Скачиваем дистрибутив Hadoop (на tmpl-jn)

Внутри tmux:
```bash
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz
```
Далее можно сделать `Ctrl+B D` или `tmux detach` для выхода из tmux с сохранением процесса.

### 6. Настраиваем SSH-ключи для пользователя `hadoop`

Возвращаемся в консоль пользователя `hadoop` (или в tmux):
```bash
ssh-keygen -t ed25519
cat ~/.ssh/id_ed25519.pub >> ~/.ssh/authorized_keys
```
Теперь копируем всю `.ssh` директорию на остальные ноды (чтобы ходить без пароля):
```bash
scp -r ~/.ssh tmpl-nn:/home/hadoop
scp -r ~/.ssh tmpl-dn-00:/home/hadoop
scp -r ~/.ssh tmpl-dn-01:/home/hadoop
```
*(Убедитесь, что права и владельцы правильные на целевых нодах: `chown -R hadoop:hadoop /home/hadoop/.ssh`.)*

### 7. Копируем дистрибутив Hadoop на остальные ноды

Заходим обратно в tmux, где уже скачан `hadoop-3.4.0.tar.gz`, и выполняем:
```bash
scp hadoop-3.4.0.tar.gz tmpl-nn:/home/hadoop
scp hadoop-3.4.0.tar.gz tmpl-dn-00:/home/hadoop
scp hadoop-3.4.0.tar.gz tmpl-dn-01:/home/hadoop
```

### 8. Распаковываем Hadoop

На **каждой** ноде (tmpl-jn, tmpl-nn, tmpl-dn-00, tmpl-dn-01):
```bash
tar -xzvf hadoop-3.4.0.tar.gz
```

### 9. Настраиваем переменные окружения

Узнаём путь до Java:
```bash
which java
readlink -f $(which java)
# Пример /usr/lib/jvm/java-11-openjdk-amd64/bin/java
```
В файле `~/.profile` пользователя `hadoop` (на каждой ноде) добавляем:
```bash
export HADOOP_HOME=/home/hadoop/hadoop-3.4.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```
И активируем изменения:
```bash
source ~/.profile
```
Проверяем версию Hadoop:
```bash
hadoop version
```
Затем при необходимости копируем `.profile` на остальные ноды:
```bash
scp ~/.profile tmpl-nn:/home/hadoop
scp ~/.profile tmpl-dn-00:/home/hadoop
scp ~/.profile tmpl-dn-01:/home/hadoop
```

### 10. Правим конфиги Hadoop

Переходим в директорию с конфигами:
```bash
cd ~/hadoop-3.4.0/etc/hadoop
```

#### 10.1. `hadoop-env.sh`
```bash
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```
*(Добавляем или раскомментируем соответствующую строку.)*

#### 10.2. `core-site.xml`
```xml
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://tmpl-nn:9000</value>
    </property>
</configuration>
```

#### 10.3. `hdfs-site.xml`
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
```

#### 10.4. `workers`
```bash
tmpl-nn
tmpl-dn-00
tmpl-dn-01
```
*(Можно также убрать из `workers` саму jn-ноду, если она не нужна в качестве DataNode.)*

### 11. Раскидываем конфиги по нодам

```bash
scp core-site.xml tmpl-nn:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp core-site.xml tmpl-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp core-site.xml tmpl-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop

scp hadoop-env.sh tmpl-nn:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp hadoop-env.sh tmpl-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp hadoop-env.sh tmpl-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop

scp hdfs-site.xml tmpl-nn:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp hdfs-site.xml tmpl-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp hdfs-site.xml tmpl-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop

scp workers tmpl-nn:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp workers tmpl-dn-00:/home/hadoop/hadoop-3.4.0/etc/hadoop
scp workers tmpl-dn-01:/home/hadoop/hadoop-3.4.0/etc/hadoop
```

### 12. Форматирование HDFS и запуск кластера

1. Переходим на NameNode (tmpl-nn):
   ```bash
   ssh tmpl-nn
   cd ~/hadoop-3.4.0/
   ```
2. Форматируем HDFS (namenode):
   ```bash
   bin/hdfs namenode -format
   ```
3. Запускаем HDFS:
   ```bash
   sbin/start-dfs.sh
   ```
   При необходимости можно запустить также `start-yarn.sh`, если нужен YARN.

### 13. Проверяем кластер

Для проверки создаём тестовую папку:
```bash
hdfs dfs -mkdir /test
hdfs dfs -ls /
# Должны увидеть /test в списке
```

Если всё настроено верно, DataNode-ноды увидят эту директорию.

**На этом базовая настройка Hadoop-кластера завершена.** 