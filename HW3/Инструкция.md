
Для удобства за базовую точку берём jump ноду **tmpl-jn**, откуда осуществляются подключения по SSH под пользователем `hadoop`.  

---

## 1. Установка и настройка PostgreSQL на NameNode

1. **Подключаемся к NameNode** (tmpl-nn):
    ```bash
    ssh tmpl-nn
    ```
   
2. **Устанавливаем PostgreSQL** (выполняем от `sudo`-пользователя `team`):
    ```bash
    sudo apt install postgresql
    ```

3. **Создаём базу данных и пользователя PostgreSQL**:
    ```bash
    sudo -i -u postgres
    psql
    ```
    Внутри `psql` выполняем команды:
    ```sql
    CREATE DATABASE metastore;
    CREATE USER hive WITH PASSWORD 'hiveMegaPass';
    GRANT ALL PRIVILEGES ON DATABASE "metastore" TO hive;
    ALTER DATABASE metastore OWNER TO hive;
    \q
    ```
    Затем выходим из-под пользователя `postgres`:
    ```bash
    exit
    ```

4. **Настраиваем доступ к PostgreSQL**:

   - В файле `/etc/postgresql/16/main/pg_hba.conf` добавляем строки, разрешающие подключения для hive c нужных IP-адресов (в данном примере показано, что нужен доступ от jump-нод `192.168.1.1` и `192.168.1.142`; замените при необходимости на реальные IP-адреса):
     ```
     host    metastore       hive            192.168.1.1/32          password
     host    metastore       hive            192.168.1.142/32        password
     ```
   - В файле `/etc/postgresql/16/main/postgresql.conf` раскомментируем или добавляем:
     ```
     listen_addresses = '*'
     ```

5. **Перезапускаем PostgreSQL**, чтобы изменения вступили в силу:
    ```bash
    sudo systemctl restart postgresql
    ```

6. **Возвращаемся на jump-нод**:
    ```bash
    exit
    ```

7. **Проверяем подключение к PostgreSQL** (уже с `tmpl-jn`):
    ```bash
    psql -h tmpl-nn -p 5432 -U hive -W -d metastore
    ```
    Если подключение успешно, можно выйти из `psql` командой `\q`.

---

## 2. Установка и настройка Hive

Дальнейшие действия выполняем на jump-ноде (tmpl-jn) под пользователем `team`, затем переключаясь на пользователя `hadoop` (или под тем пользователем, под которым вы собираетесь работать с Hive).

1. **Переходим на jump-нод** (если еще не там) и переключаемся на пользователя `hadoop`:
    ```bash
    ssh tmpl-jn
    su hadoop
    ```
2. **Скачиваем дистрибутив Hive** (пример с Hive 4.0.0-alpha-2):
    ```bash
    wget https://archive.apache.org/dist/hive/hive-4.0.0-alpha-2/apache-hive-4.0.0-alpha-2-bin.tar.gz
    tar -xzvf apache-hive-4.0.0-alpha-2-bin.tar.gz
    ```
3. **Скачиваем драйвер для PostgreSQL** в директорию `lib` Hive:
    ```bash
    cd apache-hive-4.0.0-alpha-2-bin/lib/
    wget https://jdbc.postgresql.org/download/postgresql-42.7.4.jar
    ```
   Убедитесь, что версия драйвера соответствует используемой версии PostgreSQL.

4. **Кладём файл `hive-site.xml`** (настроенный для подключения к PostgreSQL) в директорию конфигурации Hive:
    ```
    cp /путь/к/файлу/hive-site.xml ../conf/hive-site.xml
    ```
   Убедитесь, что внутри `hive-site.xml` корректно указаны параметры:
   - `javax.jdo.option.ConnectionURL` (jdbc:postgresql://tmpl-nn:5432/metastore)
   - `javax.jdo.option.ConnectionDriverName` (org.postgresql.Driver)
   - `javax.jdo.option.ConnectionUserName` (hive)
   - `javax.jdo.option.ConnectionPassword` (hiveMegaPass)

5. **Добавляем переменные окружения** в `~/.profile` (или `~/.bashrc`, при необходимости) текущего пользователя:
    ```bash
    export HIVE_HOME=/home/hadoop/apache-hive-4.0.0-alpha-2-bin
    export HIVE_CONF_DIR=$HIVE_HOME/conf
    export HIVE_AUX_JARS_PATH=$HIVE_HOME/lib/*
    export PATH=$PATH:$HIVE_HOME/bin
    ```
   Затем применяем изменения:
    ```bash
    source ~/.profile
    ```
6. **Проверяем, что Hive установился корректно**:
    ```bash
    hive --version
    ```
    Если всё настроено верно, команда выдаст версию Hive без ошибок.

---

## 3. Подготовка HDFS директорий под Hive

1. **Убедитесь, что в HDFS есть директория `/tmp`**, если нет — создайте:
    ```bash
    hdfs dfs -mkdir /tmp
    ```
2. **Создаём директорию под склад данных Hive**:
    ```bash
    hdfs dfs -mkdir -p /user/hive/warehouse
    ```
3. **Настраиваем права доступа**, чтобы Hive мог записывать временные файлы:
    ```bash
    hdfs dfs -chmod g+w /user/hive/warehouse
    hdfs dfs -chmod g+w /tmp
    ```

---

## 4. Инициализация схемы метаданных Hive в PostgreSQL

1. **Переходим в каталог с установленным Hive**:
    ```bash
    cd /home/hadoop/apache-hive-4.0.0-alpha-2-bin
    ```
2. **Инициализируем схему** (создаём таблицы метаданных в базе `metastore`):
    ```bash
    bin/schematool -dbType postgres -initSchema
    ```
    Если всё выполнено правильно, в консоли отобразится успешный результат и таблицы появятся в базе PostgreSQL.

---

## 5. Запуск HiveServer2 и подключение к Hive

1. **Запускаем HiveServer2** (можно в фоне):
    ```bash
    hive --hiveconf hive.server2.enable.doAs=false \
         --hiveconf hive.security.authorization.enable=false \
         --service hiveserver2 \
         1>> /tmp/hs2.log 2>> /tmp/hs2.log &
    ```
   - Логи сохраняются в `/tmp/hs2.log`.

2. **Подключаемся к Hive** с помощью Beeline (пример порта 5433, замените на ваш):
    ```bash
    beeline -u jdbc:hive2://tmpl-jn:5433 -n scott -p tiger
    ```
   - Здесь `scott/tiger` — это логин и пароль для тестового подключения. Логин/пароль можно не использовать или использовать любые другие, в зависимости от настройки авторизации в Hive.

---

## 6. Загрузка и проверка данных (пример с файлом из Роспатента)

Допустим, у нас уже есть в HDFS файл `/test/data-20241101-structure-20180828.csv` (скачивали в прошлых доашках), который мы хотим превратить в табличку.  

1. **Создаём базу данных**:
    ```sql
    CREATE DATABASE test;
    ```
2. **Создаём таблицу**:
    ```sql
    CREATE TABLE IF NOT EXISTS test.patent (
      `registration_number` STRING,
      `registration_date` STRING,
      `application_number` STRING,
      `application_date` STRING,
      `priority_date` STRING,
      `exhibition_priority_date` STRING,
      `paris_convention_priority_number` STRING,
      `paris_convention_priority_date` STRING,
      `paris_convention_priority_country_code` STRING,
      `initial_application_number` STRING,
      `initial_application_priority_date` STRING,
      `initial_registration_number` STRING,
      `initial_registration_date` STRING,
      `international_registration_number` STRING,
      `international_registration_date` STRING,
      `international_registration_priority_date` STRING,
      `international_registration_entry_date` STRING,
      `application_number_for_recognition_of_trademark_from_Crimea` STRING,
      `application_date_for_recognition_of_trademark_from_Crimea` STRING,
      `Crimean_trademark_application_number_for_state_registration_in_Ukraine` STRING,
      `Crimean_trademark_application_date_for_state_registration_in_Ukraine` STRING,
      `Crimean_trademark_certificate_number_in_Ukraine` STRING,
      `exclusive_rights_transfer_agreement_registration_number` STRING,
      `exclusive_rights_transfer_agreement_registration_date` STRING,
      `legally_related_applications` STRING,
      `legally_related_registrations` STRING,
      `expiration_date` STRING,
      `right_holder_name` STRING,
      `foreign_right_holder_name` STRING,
      `right_holder_address` STRING,
      `right_holder_country_code` STRING,
      `right_holder_ogrn` STRING,
      `right_holder_inn` STRING,
      `correspondence_address` STRING,
      `collective` STRING,
      `collective_users` STRING,
      `extraction_from_charter_of_the_collective_trademark` STRING,
      `color_specification` STRING,
      `unprotected_elements` STRING,
      `kind_specification` STRING,
      `threedimensional` STRING,
      `threedimensional_specification` STRING,
      `holographic` STRING,
      `holographic_specification` STRING,
      `sound` STRING,
      `sound_specification` STRING,
      `olfactory` STRING,
      `olfactory_specification` STRING,
      `color` STRING,
      `color_trademark_specification` STRING,
      `light` STRING,
      `light_specification` STRING,
      `changing` STRING,
      `changing_specification` STRING,
      `positional` STRING,
      `positional_specification` STRING,
      `actual` STRING,
      `publication_URL` STRING
    )
    ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
    WITH SERDEPROPERTIES (
      'separatorChar' = ',',
      'quoteChar' = '"',
      'escapeChar' = '\\'
    )
    STORED AS TEXTFILE
    LOCATION '/user/hive/warehouse/test.db/patent'
    TBLPROPERTIES ('skip.header.line.count' = '1');
    ```
3. **Загружаем данные** в таблицу из HDFS:
    ```sql
    USE test;
    LOAD DATA INPATH '/test/data-20241101-structure-20180828.csv'
         INTO TABLE test.patent;
    ```
4. **Проверяем наличие данных**:
    ```sql
    SELECT * FROM test.patent LIMIT 2;
    ```

Если запрос возвращает строки, значит таблица успешно создана и данные загружены.